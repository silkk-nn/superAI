{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(Xtrain[456], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.reshape(-1, 28*28)\n",
    "Xtest = Xtest.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-Hot endcoder\n",
    "def onehot(Y, nclass=10):\n",
    "    Y_ = np.zeros((Y.shape[0], nclass))\n",
    "    for i, y in enumerate(Y):\n",
    "        Y_[i, Y[i]] = 1\n",
    "    return Y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-Hot with keras\n",
    "Y = tf.keras.utils.to_categorical(Y, num_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = onehot(Ytrain)\n",
    "Ytest = onehot(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0904 - val_loss: 0.1727\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0899 - val_loss: 0.1691\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0894 - val_loss: 0.1645\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0889 - val_loss: 0.1597\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0884 - val_loss: 0.1548\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0878 - val_loss: 0.1506\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0873 - val_loss: 0.1464\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0867 - val_loss: 0.1419\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0861 - val_loss: 0.1369\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0854 - val_loss: 0.1322\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0847 - val_loss: 0.1276\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0839 - val_loss: 0.1221\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0831 - val_loss: 0.1169\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0822 - val_loss: 0.1116\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0813 - val_loss: 0.1072\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0803 - val_loss: 0.1035\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0792 - val_loss: 0.0998\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0781 - val_loss: 0.0969\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0770 - val_loss: 0.0939\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0757 - val_loss: 0.0916\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0745 - val_loss: 0.0891\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0732 - val_loss: 0.0864\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0718 - val_loss: 0.0836\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0704 - val_loss: 0.0814\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0689 - val_loss: 0.0787\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0675 - val_loss: 0.0757\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0659 - val_loss: 0.0727\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0644 - val_loss: 0.0698\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0628 - val_loss: 0.0670\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0612 - val_loss: 0.0637\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0597 - val_loss: 0.0608\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0581 - val_loss: 0.0585\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0565 - val_loss: 0.0557\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0550 - val_loss: 0.0536\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0534 - val_loss: 0.0520\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0520 - val_loss: 0.0507\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0506 - val_loss: 0.0495\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0492 - val_loss: 0.0486\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0467 - val_loss: 0.0473\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0456 - val_loss: 0.0465\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0445 - val_loss: 0.0459\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0435 - val_loss: 0.0453\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0426 - val_loss: 0.0448\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0417 - val_loss: 0.0443\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0409 - val_loss: 0.0439\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0401 - val_loss: 0.0436\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0394 - val_loss: 0.0432\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0387 - val_loss: 0.0427\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0380 - val_loss: 0.0423\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0374 - val_loss: 0.0418\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0368 - val_loss: 0.0414\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0363 - val_loss: 0.0410\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0358 - val_loss: 0.0408\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0348 - val_loss: 0.0403\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0343 - val_loss: 0.0398\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0338 - val_loss: 0.0393\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0333 - val_loss: 0.0387\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0328 - val_loss: 0.0381\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0323 - val_loss: 0.0374\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0318 - val_loss: 0.0364\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0313 - val_loss: 0.0355\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0308 - val_loss: 0.0347\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0304 - val_loss: 0.0338\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0299 - val_loss: 0.0330\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0294 - val_loss: 0.0325\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0290 - val_loss: 0.0319\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0286 - val_loss: 0.0313\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0281 - val_loss: 0.0307\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0277 - val_loss: 0.0302\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0273 - val_loss: 0.0297\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0269 - val_loss: 0.0293\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0266 - val_loss: 0.0290\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0259 - val_loss: 0.0280\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0255 - val_loss: 0.0276\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0252 - val_loss: 0.0273\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0249 - val_loss: 0.0269\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0246 - val_loss: 0.0265\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0243 - val_loss: 0.0262\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0240 - val_loss: 0.0257\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0238 - val_loss: 0.0255\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0235 - val_loss: 0.0254\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0233 - val_loss: 0.0252\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0231 - val_loss: 0.0250\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - val_loss: 0.0248\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0222 - val_loss: 0.0244\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0220 - val_loss: 0.0243\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0217 - val_loss: 0.0240\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0215 - val_loss: 0.0239\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0210 - val_loss: 0.0233\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - val_loss: 0.0231\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0207 - val_loss: 0.0230\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0206 - val_loss: 0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274bc3c9850>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##768->200->200->10\n",
    "d_in = (Xtrain.shape[1], )\n",
    "model =  tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(200, input_shape=d_in,\n",
    "                                activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "             optimizer=tf.keras.optimizers.SGD(learning_rate=0.001))\n",
    "\n",
    "model.fit(Xtrain/255., Ytrain, epochs=100, validation_data=(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869\n"
     ]
    }
   ],
   "source": [
    "Z = model.predict(Xtest/255.)\n",
    "print(np.sum(Z.argmax(axis=1) == Ytest.argmax(axis=1))/len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-95354999a3f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "Z[1].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
